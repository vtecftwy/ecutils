{
 "cells": [
  {
   "cell_type": "raw",
   "id": "42e49f12",
   "metadata": {},
   "source": [
    "description: Utility Functions that can be used ML jobs and Kaggle. Includes all stable\n",
    "  utility functions.\n",
    "output-file: ml.html\n",
    "title: '`ml` module - Utility functions for Machine Learning'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcde16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a4f90",
   "metadata": {},
   "source": [
    "Reference for kaggle API: https://github.com/Kaggle/kaggle-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26099178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from scipy import stats\n",
    "from scipy.cluster import hierarchy as hc\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import configparser\n",
    "import datetime as dt\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4029f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def are_features_consistent(train_df, test_df, dependent_variables=None):\n",
    "    \"\"\"Verifies that features in training and test sets are consistent\n",
    "\n",
    "    Training set and test set should have the same features/columns, except for the dependent variables\n",
    "\n",
    "    train_dr: pd.DataFrame      training dataset\n",
    "    test_df:  pd.DataFrame      test dataset\n",
    "    dependent_variables: list   list of column names for the dependent variables\n",
    "    \"\"\"\n",
    "    if dependent_variables is None:\n",
    "        features_training_set = train_df.columns\n",
    "    else:\n",
    "        features_training_set = train_df.drop(dependent_variables, axis=1).columns\n",
    "    features_test_set = test_df.columns\n",
    "    features_diff = set(features_training_set).symmetric_difference(features_test_set)\n",
    "    assert features_diff == set(), f\"Discrepancy between training and test feature set: {features_diff}\"\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46fe2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cluster_columns(df, figsize=(10,6), font_size=12):\n",
    "    \"\"\"Plot dendogram based on columns' spearman correlation coefficients\n",
    "\n",
    "    First seen on fastai repository\n",
    "    \"\"\"\n",
    "    corr = np.round(stats.spearmanr(df).correlation, 4)\n",
    "    corr_condensed = hc.distance.squareform(1-corr)\n",
    "    z = hc.linkage(corr_condensed, method='average')\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    hc.dendrogram(z, labels=df.columns, orientation='left', leaf_font_size=font_size)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff45393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_cli(cmd='ls -l'):\n",
    "    \"\"\"Wrapper to use subprocess.run with passed command, and print the shell messages\n",
    "\n",
    "    cmd: str    cli command to execute\n",
    "    \"\"\"\n",
    "    p = subprocess.run(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "    print(str(p.stdout, 'utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d17d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_config_value(section, key, path_to_config_file=None):\n",
    "    \"\"\"Returns the value corresponding to the key-value pair in the configuration file (configparser format)\n",
    "\n",
    "    By defaults, it is assumed that the configuration file is saved on google drive. If not, pass a proper Path object.\n",
    "    The configuration file must be in the format of configparser (https://docs.python.org/3/library/configparser.html)\n",
    "\n",
    "    Parameters:\n",
    "        section (str):          name of the section where the key-value pair is stored\n",
    "        key (str):              name of the key\n",
    "        path_to_config_file(Path or str): path to the configparser configuration file\n",
    "\n",
    "    Return (str):               value in the key-value pair stored\n",
    "    \"\"\"\n",
    "    if path_to_config_file is None:\n",
    "        path_to_config_file = Path(f\"/content/gdrive/My Drive/config-api-keys.cfg\")\n",
    "    elif isinstance(path_to_config_file, str):\n",
    "        path_to_config_file = Path(f\"/content/gdrive/My Drive/{path_to_config_file}\")\n",
    "\n",
    "    msg = f\"Cannot find file {path_to_config_file}. Please check the path or add the config file at that location\"\n",
    "    assert path_to_config_file.is_file(), msg\n",
    "\n",
    "    configuration = configparser.ConfigParser()\n",
    "    configuration.read(path_to_config_file)\n",
    "    return configuration[section][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fastbook_on_colab():\n",
    "    \"\"\"\n",
    "    Set up environment to run fastbook notebooks for colab\n",
    "\n",
    "    Code from notebook:\n",
    "    # Install fastbook and dependencies\n",
    "    !pip install -Uqq fastbook\n",
    "\n",
    "    # Load utilities and install them\n",
    "    !wget -O utils.py https://raw.githubusercontent.com/vtecftwy/fastbook/walk-thru/utils.py\n",
    "    !wget -O fastbook_utils.py https://raw.githubusercontent.com/vtecftwy/fastbook/walk-thru/fastbook_utils.py\n",
    "\n",
    "    from fastbook_utils import *\n",
    "    from utils import *\n",
    "\n",
    "    # Setup My Drive\n",
    "    setup_book()\n",
    "\n",
    "    # Download images and code required for this notebook\n",
    "    import os\n",
    "    os.makedirs('images', exist_ok=True)\n",
    "    !wget -O images/chapter1_cat_example.jpg https://raw.githubusercontent.com/vtecftwy/fastai-course-v4/master/nbs/images/chapter1_cat_example.jpg\n",
    "    !wget -O images/cat-01.jpg https://raw.githubusercontent.com/vtecftwy/fastai-course-v4/walk-thru/nbs/images/cat-01.jpg\n",
    "    !wget -O images/cat-02.jpg https://raw.githubusercontent.com/vtecftwy/fastai-course-v4/walk-thru/nbs/images/cat-02.jpg\n",
    "    !wget -O images/dog-01.jpg https://raw.githubusercontent.com/vtecftwy/fastai-course-v4/walk-thru/nbs/images/dog-01.jpg\n",
    "    !wget -O images/dog-02.jpg https://raw.githubusercontent.com/vtecftwy/fastai-course-v4/walk-thru/nbs/images/dog-01.jpg\n",
    "\n",
    "    \"\"\"\n",
    "    instructions = ['pip install -Uqq fastbook',\n",
    "                    'wget -O utils.py https://raw.githubusercontent.com/vtecftwy/fastbook/walk-thru/utils.py',\n",
    "                    'wget -O fastbook_utils.py https://raw.githubusercontent.com/vtecftwy/fastbook/walk-thru/fastbook_utils.py'\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd24c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def kaggle_setup_colab(path_to_config_file=None):\n",
    "    \"\"\"Update kaggle API and create security key json file from config file on Google Drive\n",
    "\n",
    "    Kaggle API documentation: https://github.com/Kaggle/kaggle-api\n",
    "\n",
    "    Kaggle API Token to be placed as a json file at the following location:\n",
    "          ~/.kaggle/kaggle.json\n",
    "          %HOMEPATH%\\.kaggle\\kaggle.json\n",
    "\n",
    "    To access Kaggle with API, a security key needs to be placed in the correct location on colab.\n",
    "    config.cfg file must include the following lines:\n",
    "        [kaggle]\n",
    "            kaggle_username = kaggle_user_name\n",
    "            kaggle_key = API key provided by kaggle\n",
    "\n",
    "        Info on how to get your api key (kaggle.json) here: https://github.com/Kaggle/kaggle-api#api-credentials\n",
    "\n",
    "    path_to_config_file: str or Path:   path to the configuration file (e.g. config.cfg)\n",
    "\n",
    "    \"\"\"\n",
    "    # Create API security key file\n",
    "    path_to_kaggle = Path('/root/.kaggle')\n",
    "    os.makedirs(path_to_kaggle, exist_ok=True)\n",
    "\n",
    "    username = get_config_value('kaggle', 'kaggle_username', path_to_config_file=path_to_config_file)\n",
    "    key = get_config_value('kaggle', 'kaggle_key', path_to_config_file=path_to_config_file)\n",
    "\n",
    "    api_token = {\"username\": username, \"key\": key}\n",
    "    with open(path_to_kaggle / 'kaggle.json', 'w') as file:\n",
    "        json.dump(api_token, file)\n",
    "        os.fchmod(file.fileno(), 600)\n",
    "\n",
    "    # Update kaggle API software\n",
    "    run_cli('pip install -Uqq kaggle --upgrade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e3d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def kaggle_list_files(code=None, mode='competitions'):\n",
    "    \"\"\"List all files available in the competition or dataset for the passed code\"\"\"\n",
    "    if code is None:\n",
    "        print(f\"code is None, please provide the code of the kaggle competition or dataset\")\n",
    "        return 'Failed'\n",
    "    elif mode not in ['competitions', 'datasets']:\n",
    "        print(f\"mode must be either 'competitions' or 'datasets', not {mode}\")\n",
    "        return 'Failed'\n",
    "    else:\n",
    "        print(f\"Listing the files available for {mode}: <{code}>\")\n",
    "        run_cli(f\"kaggle {mode} files {code}\")\n",
    "\n",
    "    if mode == 'competitions':\n",
    "        print(f\"{'=' * 140}\")\n",
    "        print(f\"Make sure to set the parameters for <{code}> in next cell:\")\n",
    "        print(f\" - kaggle_project_folder_name: string with name of the project folder\")\n",
    "        print(f\" - train_files: list of files to place into the <train> folder\")\n",
    "        print(f\" - test_files: list of files to place into the <test> folder\")\n",
    "        print(f\" - submit_files: list of files to place into the <submit> folder\")\n",
    "        print(f\"{'=' * 140}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9fbd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def kaggle_download_competition_files(competition_code=None, train_files=[], test_files=[], submit_files=[], project_folder='ds' ):\n",
    "    \"\"\"download all files for passed competition, unzip them if required, move them to train, test and submit folders\n",
    "\n",
    "    competition_code: str       code of the kaggle competition\n",
    "    train_files: list of str    names of files to be moved into train folder\n",
    "    test_files: list of str     names of files to be moved into test folder\n",
    "    submit_files: list of str   names of files to be moved into submit folder\n",
    "    \"\"\"\n",
    "    if competition_code is None:\n",
    "        print(f\"competition_code is None, please provide the code of the kaggle competition\")\n",
    "        return 'Failed'\n",
    "    else:\n",
    "        list_of_datasets = {'train': train_files,\n",
    "                            'test': test_files,\n",
    "                            'submit': submit_files}\n",
    "\n",
    "        # creating a project directory and set paths\n",
    "        if not os.path.exists(project_folder):\n",
    "            os.makedirs(project_folder)\n",
    "\n",
    "        path2datasets = Path(f\"/content/{project_folder}\")\n",
    "        path2datasets_str = str(path2datasets.absolute())\n",
    "\n",
    "        # download all files from kaggle\n",
    "        run_cli(f\"kaggle competitions download -c {competition_code} -p {path2datasets}\")\n",
    "\n",
    "        print(f\"{'=' * 140}\")\n",
    "        print('Downloaded files:')\n",
    "        for f in [item for item in path2datasets.iterdir() if item.is_file()]:\n",
    "            print(f\" - {f}\")\n",
    "        print(f\"{'=' * 140}\")\n",
    "\n",
    "        # Unzip all zipped files\n",
    "        for f in path2datasets.glob('*.zip'):\n",
    "            print(f\"Unzipping {f.name}\")\n",
    "            zip_f = ZipFile(f)\n",
    "            zip_f.extractall(path=path2datasets)\n",
    "            os.remove(f)\n",
    "        print(f\"{'=' * 140}\")\n",
    "\n",
    "        # Move all data files to the correct data folder\n",
    "        for dataset_folder, files in list_of_datasets.items():\n",
    "            if not os.path.exists(f'{project_folder}/{dataset_folder}'):\n",
    "                os.makedirs(f'{project_folder}/{dataset_folder}')\n",
    "\n",
    "            for f in files:\n",
    "                print(f\"Moving {f} to {dataset_folder}\")\n",
    "                p2f = path2datasets / f\n",
    "                if p2f.suffix == '.csv':\n",
    "                    shutil.move(path2datasets / f, path2datasets / dataset_folder / f)\n",
    "                else:\n",
    "                    msg = f\"Does not support {p2f.name}'s extension {p2f.suffix}\"\n",
    "                    raise RuntimeError(msg)\n",
    "\n",
    "        print(f\"{'=' * 140}\")\n",
    "        print('Done loading Kaggle files and moving them to corresponding folders')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
